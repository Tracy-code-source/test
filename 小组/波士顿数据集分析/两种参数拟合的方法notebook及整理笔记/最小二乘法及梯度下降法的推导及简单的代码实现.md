# 线性回归方程参数求解

## **不妨令y为拟合值， x为数据特征， w为权重参数**

*以上量均作为矩阵存在*
**拟合方程： y. = xw,  假设x有m个特征，n个样本**

## 法一 ： 最小二乘法 

## （原理：基于均方误差，通过令其最小求解参数）

*为方便书写，将拟合值记作y.*
$$
Loss = \sum_1^m(y. - y)^2
$$


以上为拟合的损失函数， 令其最小
$$
\ggg (y. -y)^T(y. - y) = (xw -y)^T(xw - y)
$$

$$
\ggg w^Tx^Txw - w^Tx^Ty - y^Txw -y^Ty
$$

**这里观察注意到**
$$
w^Tx^Ty，y^Txw 这两项互为对方转置矩阵并为标量
$$
再次化简
$$
\ggg w^Tx^Txw - 2y^Txw +y^Ty
$$
令此时对w求偏导

得
$$
\partial Loss/\partial w = 2x^Txw -2x^Ty
$$
令上式等于零

得
$$
w = (x^Tx)^-1 (x^Ty)
$$
 以下为代码实现

```python
# 导入数据处理库及数据可视化库
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# 设计导入数据函数并将其转化为矩阵
def dataImport():
    data = pd.read_csv(r'C:\Users\HUANG\Downloads\house_data.csv', delimiter = ',')
    m = data.shape[1] - 1; # 特征数， 减去最后一列
    # 这里单纯进行数据计算模拟，未筛选数据
    X = data.iloc[:, 0: m].values # 读取0到m-1列
    Y = data.iloc[:, -1].values.reshape(-1, 1) # 读取最后一列，并转为二维
    return X, Y
    
data_x,data_y = dataImport()
X = np.insert(data_x, 0, values = 1, axis = 1) # 在特征矩阵前加入一列1，构成可用于计算的矩阵

# 实现最小二乘公式
k = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(data_y)
    
```

## 法二： 梯度下降法

**一元：假设一个点在曲线上，它要如何快速到达函数的局部最小值？ Ans:  每一步都沿着曲线切线方向移动**

为近似某个函数，不妨对其进行泰勒展开
$$
f(x) \approx f(x^k) + (x - x^k)\nabla f(x^k)
$$
进一步推导得
$$
f(x)\approx f(x^k) + \lambda \nu \nabla f(x^k)    --（1）
$$
上式lambda为（x - x^k）的模， v为 （x - x^k)方向单位向量，二者结合即为步长

*显然函数希望每次呈下降趋势*

那么容易得到 
$$
\lambda \nu \nabla f(x^k) < 0
$$
由于lambda为标量，则只需考虑
$$
\nu \nabla f(x^k) < 0
$$
问题转化为两向量相乘， 回溯到目的是达到函数局部最小值，且nablaf（x^k）已知

此时问题转化为求v,根据上式（1），有以下关系式
$$
x - x^k = \lambda \nu
$$
 回想两向量相乘最小，cos（e1, e2）取 -1， 得到v
$$
\nu = - \nabla f(x^k) / ||\nabla f(x^k)||
$$
得到
$$
x = x^k - \lambda (\nabla f(x^ k) / ||\nabla f(x^k)||)
$$
化简得到迭代公式 （注意此处lambda非上式lambda， 存在标量的融合）
$$
x^(k + 1) = x^k - \lambda \nabla f(x^k) 
$$
 将x替换成参数w得到更新规则
$$
w := w - \lambda (\partial Loss / \partial w)
$$
由于上述采用一元推导，此处不妨令f(x) = x^2

求其最小值

```python
# 导入相应库
import numpy as np
import matplotlib.pyplot as plt

# 尝试用梯度下降法求解 f(x) = x^2 最小值
def Build():
    x = np.linspace(-4, 4, 100) # 生成-4到4一百个等间距数值，并赋值给x
    y = x ** 2
    plt.plot(x, y)
    
Build() #调用函数显示图像

# 因为是一元，梯度直接对其求导
# 得到导数2x

# 初始化迭代起点x,alaph,迭代次数
x = 3
alaph = 0.2
it = 200

for i in range(0,it, 1):
    x = x - alaph * (2 * x)
print(x)
# 1.2804756714360726e-44
# 非常接近0, 0.00000000000000000000000000000000000000000012804756714360726

# 再测一组
x = 2
alaph = 0.4
it = 100

for i in range(0, it, 1):
    x = x - alaph * (2 * x)
print(x)
# 2.53530120045641e-70
# 几乎就是零
```

